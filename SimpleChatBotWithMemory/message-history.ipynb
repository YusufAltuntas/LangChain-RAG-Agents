{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Aşağıda ismimizi verdik ve bir cevap döndü. ikinci mesaj olarak ismimizin ne oldupunu sorsaydık bunu bilmediğini söyleyecekti. çünkü her yeni mesajda yeni bir sesssion açıyormuşuz gibi davranıyor.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Yusuf, nice to meet you. How can I assist you today?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "message = HumanMessage(content=\"Hello, my name is Yusuf\")\n",
    "response = model.invoke([message])\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Burada bir session açıp önce kendi mesajımızı, sonra AI ın verdiği cevabı yazdırdık. sonrasında ismimizi sorduğumuzda buna cevap verdi, konuşma bir session içindeymiş gibi davrandı. Fakat bu yöntem mantıksız ve işlevsel değil. Elimizle session açıp mesaj girerek olmaz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Yusuf.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    HumanMessage(content=\"Hello, my name is yusuf\"),\n",
    "    AIMessage(content=\"Hello Yusuf, how can i help you today?\"),\n",
    "    HumanMessage(content=\"What is my name?\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Yusuf! How can I assist you today?\n",
      "Your name is Yusuf.\n",
      "Döngü sonlandırılıyor.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id : str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "config = {\"configurable\": {\"session_id\": \"abcde123\"}}\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "while True: \n",
    "    user_input = input(\">\")\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"çıkış\"]:\n",
    "        print(\"Session sonlandiriliyor.\")\n",
    "        break\n",
    "\n",
    "    response = with_message_history.invoke(\n",
    "        [\n",
    "            HumanMessage(content=user_input)\n",
    "        ],\n",
    "        config=config,\n",
    "    )\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Çıktıyı stream olarak alma:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure !  Gravity  is  the  force  that  pulls  objects  with  mass  towards  each  other .  It  is  what  keeps  us  grounded  on  Earth  and  is  responsible  for  the  motion  of  planets ,  stars ,  and  galaxies .  According  to  Albert  Einstein 's  theory  of  general  rel ativity ,  gravity  is  the  result  of  the  curvature  of  spac etime  caused  by  massive  objects .  Session sonlandiriliyor.\n"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id : str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model\n",
    "config = {\"configurable\": {\"session_id\": \"abcde123\"}}\n",
    "with_message_history = RunnableWithMessageHistory(chain, get_session_history)\n",
    "\n",
    "while True: \n",
    "    user_input = input(\">\")\n",
    "\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"çıkış\"]:\n",
    "        print(\"Session sonlandiriliyor.\")\n",
    "        break\n",
    "\n",
    "    for r in with_message_history.stream(\n",
    "        [\n",
    "            HumanMessage(content=user_input)\n",
    "        ],\n",
    "        config=config,\n",
    "    ):\n",
    "        print(r.content, end=\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
